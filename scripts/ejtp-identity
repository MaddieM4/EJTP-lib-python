#!/usr/bin/env python
'''
This file is part of the Python EJTP library.

The Python EJTP library is free software: you can redistribute it 
and/or modify it under the terms of the GNU Lesser Public License as
published by the Free Software Foundation, either version 3 of the 
License, or (at your option) any later version.

the Python EJTP library is distributed in the hope that it will be 
useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser Public License for more details.

You should have received a copy of the GNU Lesser Public License
along with the Python EJTP library.  If not, see 
<http://www.gnu.org/licenses/>.
'''

__doc__ = '''ejtp-identity

A simple little script for EJTP identity management from the command line.

Usage:
    ejtp-identity ( list ) [--by-file|--cache-source=<cache-source>]
    ejtp-identity ( details ) [-ep] <name> [--cache-source=<cache-source>]
    ejtp-identity ( rm ) [-A] <names>... [--cache-source=<cache-source>]
    ejtp-identity ( new ) --name=<name> --location=<location> --encryptor=<encryptor>
    ejtp-identity ( merge ) <filename>
    ejtp-identity ( set ) <name> --args=<args> [--cache-source=<cache-source>]
    ejtp-identity -h | --help
    ejtp-identity --version

Options:
    -h --help       Show this help message
    -e --export     Wrap identity in the cache structure [default: False]
    -p --public     Convert the encryptor to its public counterpart [default: False]
'''

import os
import sys
import json

from ejtp.config import test_filenames
from ejtp.util.py2and3 import JSONBytesEncoder
from ejtp.crypto.encryptor import make
from ejtp.vendor.docopt import docopt

class JSONEncoder(json.JSONEncoder):

    def default(self, obj):
        try:
            return json.JSONEncoder.default(self, obj)
        except TypeError:
            return JSONBytesEncoder(obj)


def data_per_file(cache_source, env_var='EJTP_IDENTITY_CACHE_PATH'):
    files = []
    if cache_source:
        files = test_filenames([cache_source])
    if not files:
        files = test_filenames([], env_var=env_var)

    for fname in files:
        with open(fname) as f:
            yield fname, json.load(f)

def list_identities(cache_source, by_file=False, name=None):
    for fname, data in data_per_file(cache_source):
        fname_printed = False
        for identity in data.values():
            if by_file and not fname_printed:
                print(os.path.relpath(fname))
                fname_printed = True
            if not name or name == identity['name']:
                print('%s (%s)' % (identity['name'], identity['encryptor'][0]))

def identity_details(cache_source, name, export=False, public=False):
    for fname, data in data_per_file(cache_source):
        for identity in data.values():
            if identity['name'] == name:
                if public:
                    encryptor = make(identity.get('encryptor'))
                    identity['encryptor'] = encryptor.public()
                obj = identity
                if export:
                    obj = {json.dumps(identity.get('location')): identity}
                print(json.dumps(obj, indent=2, cls=JSONEncoder))

def new_identity(name, location, encryptor, **kwargs):
    data = {
        'name': name,
        'location': location,
        'encryptor': encryptor
    }
    data.update(kwargs)
    print(json.dumps({json.dumps(data['location']): data}, indent=2, cls=JSONEncoder))

def merge(filename, data_to_merge):
    with open(filename, 'r') as f:
        data = json.load(f)

    data.update(**data_to_merge)

    with open(filename, 'w') as f:
        json.dump(data, f)

def set_attribute(cache_source, name, **kwargs):
    found = False
    for fname, data in data_per_file(cache_source):
        with open(fname, 'r') as f:
            for identity in data.values():
                if identity['name'] == name:
                    identity.update(**kwargs)
                    found = True
        if found:
            with open(fname, 'w') as f:
                json.dump(data, f)

def rm_identities(cache_source, rm_all=False, *names):
    names_found = {}
    keys_per_file = {}
    for fname, data in list(data_per_file(cache_source)):
        for key, identity in data.items():
            name = identity['name']
            if name in names:
                if not rm_all and name in names_found:
                    print('Identity %s found in multiple files:\n' % name)
                    list_identities(cache_source, by_file=True, name=name)
                    print('\nUse --cache-source to specify which file to delete ' +
                        'from or use -A to delete from all sources.')
                    quit(1)
                else:
                    names_found[name] = []
                names_found[name].append(fname)
                if fname not in keys_per_file:
                    keys_per_file[fname] = []
                keys_per_file[fname].append(key)

    for fname, keys in keys_per_file.items():
        with open(fname) as f:
            data = json.load(f)
        for key in keys:
            identity = data.pop(key)
            print('%s removed from file %s' % (identity['name'], fname))
        with open(fname, 'w') as f:
            json.dump(data, f)

    for name in set(names) - set(names_found.keys()):
        print('%s not found in any cache file' % name)

def main(argv):
    arguments = docopt(__doc__, argv=argv[1:],
        version='ejtp-identity 0.9.5')

    cache_source = arguments.get('--cache-source')

    if arguments.get('list'):
        list_identities(cache_source, by_file=arguments.get('--by-file'))

    if arguments.get('details'):
        identity_details(cache_source, arguments['<name>'], arguments['--export'], arguments['--public'])

    if arguments.get('new'):
        name = arguments.get('--name')
        location = json.loads(arguments.get('--location'))
        encryptor = json.loads(arguments.get('--encryptor'))
        new_identity(name, location, encryptor)

    if arguments.get('merge'):
        filename = arguments.get('<filename>')
        data_to_merge = json.load(sys.stdin)
        merge(filename, data_to_merge)

    if arguments.get('set'):
        args = json.loads(arguments.get('--args'))
        set_attribute(cache_source, arguments.get('<name>'), **args)

    if arguments.get('rm'):
        rm_identities(cache_source, arguments.get('-A'), *arguments.get('<names>'))

if __name__ == '__main__':
    main(sys.argv)
